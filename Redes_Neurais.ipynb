{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Redes_Neurais.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbKKhLrthJM37et9wys3Hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santanaemmanuel/redes_neurais_CESAR_SCHOOL/blob/main/Redes_Neurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Data\n",
        "Esta primeira etapa tem como objetivo carregar os datasets"
      ],
      "metadata": {
        "id": "PmkNdSIgT62O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuV1_FCETrT9"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make transforms and use data loaders\n",
        "\n",
        "# We'll use these a lot, so make them variables\n",
        "mean_nums = [0.485, 0.456, 0.406]\n",
        "std_nums = [0.229, 0.224, 0.225]\n",
        "\n",
        "chosen_transforms = {'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean_nums, std_nums)\n",
        "]), 'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean_nums, std_nums)\n",
        "]),\n",
        "}"
      ],
      "metadata": {
        "id": "ikiFEf4HYOw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the directory for the data\n",
        "data_dir = 'PetImages/'\n",
        "\n",
        "# Use the image folder function to create datasets\n",
        "chosen_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), chosen_transforms[x]) for x in ['train', 'val']}"
      ],
      "metadata": {
        "id": "jZyOR0e9YRAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make iterables with the dataloaders\n",
        "dataloaders = {x: torch.utils.data.DataLoader(chosen_datasets[x], batch_size=4,\n",
        "  shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}"
      ],
      "metadata": {
        "id": "X1FtbEvYYVtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes = {x: len(chosen_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = chosen_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "rd-huQLsYY77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_sizes)\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "FdCmeCTdYZjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo\n",
        "O modelo resnet utilizado será o não treinado."
      ],
      "metadata": {
        "id": "_YKFSx57YgXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the model\n",
        "# load in pretrained and reset final fully connected\n",
        "\n",
        "res_mod = models.resnet34(pretrained=False)\n",
        "\n",
        "num_ftrs = res_mod.fc.in_features\n",
        "res_mod.fc = nn.Linear(num_ftrs, 2)"
      ],
      "metadata": {
        "id": "XVhdnthWYb_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_mod = res_mod.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(res_mod.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "KdKUGBmvZFn5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}